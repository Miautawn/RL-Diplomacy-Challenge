{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511eb14e-b585-4a46-bc12-250d2a348541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "from utilities.utility_functions import decompress_dict\n",
    "from settings import MODEL_DATA_PATHS, DATA_BLUEPRINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8229b48-90b0-44b4-a9c5-5db568d1c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6a67a30-6fd6-4081-8c3b-26506e9fbfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiplomacyDataset(IterableDataset):\n",
    "    def __init__(self, file_path, shuffle, shuffle_buffer_size) -> None:\n",
    "        super(DiplomacyDataset).__init__()\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        self.shuffle = shuffle\n",
    "        self.shuffle_buffer_size = shuffle_buffer_size\n",
    "        \n",
    "        if self.shuffle and self.shuffle_buffer_size <= 1:\n",
    "            raise ValueError(\"Bad shuffle buffer size.\"\\\n",
    "                            \"If you want to shuffle the iterable data, you have to define a positive > 1 shuffle buffer size.\"\\\n",
    "                            f\"\\nGot 'shuffle': {self.shuffle}, shuffle_buffer_size: {self.shuffle_buffer_size}\")\n",
    "        \n",
    "    def sequential_iterator(self):\n",
    "        # return iter(range(100))\n",
    "        return open(self.file_path, \"r\")\n",
    "        \n",
    "    def shuffle_iterator(self):\n",
    "        shuffle_buffer = []\n",
    "        local_iterator = self.sequential_iterator()\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # fill up the initial buffer\n",
    "            for _ in range(self.shuffle_buffer_size):\n",
    "                shuffle_buffer.append(next(local_iterator))\n",
    "        except StopIteration:\n",
    "            # in the scenario of either too small dataset file or too big buffer size,\n",
    "            # shrink the shuffle buffer\n",
    "\n",
    "            LOGGER.info(\"Either the dataset file is too small, or shuffle buffer size is too big for the file. \"\\\n",
    "                        \"Shrinking the buffer...\")\n",
    "            self.shuffle_buffer_size = len(shuffle_buffer)\n",
    "            \n",
    "        # main loop\n",
    "        while True:\n",
    "            remove_index = random.randint(0, len(shuffle_buffer) - 1)\n",
    "            yield shuffle_buffer.pop(remove_index)\n",
    "            \n",
    "            try:\n",
    "                shuffle_buffer.append(next(local_iterator))\n",
    "            except StopIteration:\n",
    "                break\n",
    "                \n",
    "        while len(shuffle_buffer) > 0:\n",
    "            remove_index = random.randint(0, len(shuffle_buffer) - 1)\n",
    "            yield shuffle_buffer.pop(remove_index)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \n",
    "        if(self.shuffle):\n",
    "            self.iterator = self.shuffle_iterator()\n",
    "        else:\n",
    "            self.iterator = self.sequential_iterator()\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def __next__(self):\n",
    "        item = next(self.iterator)\n",
    "        item = decompress_dict(item)\n",
    "        # print(item[\"decoer_inputs\"])\n",
    "        # return {\"a\": item[\"request_id\"], \"b\": item[\"decoder_lengths\"]}\n",
    "        # return (12, \"ba\", np.array([4,5,6]))\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f10c2af-7011-447c-b677-89fe6d820c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "shuffle = True\n",
    "shuffle_buffer_size = 10\n",
    "file_path = \"data/model_data/full_dataset_training.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef11e484-f44d-409d-b156-a9551214f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiplomacyDataset(file_path = file_path, shuffle = shuffle, shuffle_buffer_size = shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07aa8a4e-ef8b-4803-8995-b583e267a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Modified default pytorch collate function.\n",
    "    It is meant to collate the received dictionary values onto original keys,\n",
    "    also pad the non-fixed dimension features to max length of their group per batch.\n",
    "    \n",
    "    If you modify the project, please pay attention to this function,\n",
    "    as it single-purpose and should be extented.\n",
    "    \"\"\"\n",
    "    element = batch[0]\n",
    "    \n",
    "    # scalars\n",
    "    if isinstance(element, float):\n",
    "        return torch.tensor(batch, dtype=torch.float64)\n",
    "    elif isinstance(element, int):\n",
    "        return torch.tensor(batch)\n",
    "    elif isinstance(element, str):\n",
    "        return batch\n",
    "    \n",
    "    # data structures\n",
    "    elif isinstance(element, list):\n",
    "        \n",
    "        first_list_element = element[0]\n",
    "        if isinstance(first_list_element, list):\n",
    "            list_type = custom_collate_fn(first_list_element).dtype\n",
    "        else:\n",
    "            list_type = custom_collate_fn(element).dtype\n",
    "            \n",
    "        return torch.tensor(batch, dtype = list_type)\n",
    "        \n",
    "    elif isinstance(element, dict):\n",
    "        return dict({key: custom_collate_fn([dictionary[key] for dictionary in batch]) for key in element})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80a18a81-b689-4857-8ea6-cbeb5308ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size = batch_size, collate_fn = custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc35c5f8-f633-43da-98aa-08d71294c3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'request_id': {'shape': [], 'type': 'static'},\n",
       " 'player_seed': {'shape': [], 'type': 'static'},\n",
       " 'board_state': {'shape': [81, 35], 'type': 'static'},\n",
       " 'board_alignments': {'shape': [None], 'type': 'variable'},\n",
       " 'prev_orders_state': {'shape': [1, 81, 40], 'type': 'static'},\n",
       " 'decoder_inputs': {'shape': [None], 'type': 'variable'},\n",
       " 'decoder_lengths': {'shape': [], 'type': 'static'},\n",
       " 'candidates': {'shape': [None], 'type': 'variable'},\n",
       " 'noise': {'shape': [], 'type': 'static'},\n",
       " 'temperature': {'shape': [], 'type': 'static'},\n",
       " 'dropout_rate': {'shape': [], 'type': 'static'},\n",
       " 'current_power': {'shape': [], 'type': 'static'},\n",
       " 'current_season': {'shape': [], 'type': 'static'},\n",
       " 'draw_target': {'shape': [], 'type': 'static'},\n",
       " 'value_target': {'shape': [], 'type': 'static'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_BLUEPRINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cdc1fac-0e11-4cab-a190-2c179bad42ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 81])\n",
      "torch.Size([1, 3, 81])\n",
      "torch.Size([1, 3, 81])\n",
      "torch.Size([1, 4, 81])\n",
      "torch.Size([1, 6, 81])\n",
      "torch.Size([1, 4, 81])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "ba = None\n",
    "for batch in dataloader:\n",
    "    ba = batch\n",
    "    print(batch[\"board_alignments\"].shape)\n",
    "    \n",
    "    if i == 5:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1fdca66-1979-4a54-b538-760e937e9ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 81)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ba[\"board_alignments\"].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f8e0212-1277-4214-83f3-57603b45a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.array([1,2]), np.array([3,4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e83a43b-d5d5-4db1-9b63-1574fa85aa76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
