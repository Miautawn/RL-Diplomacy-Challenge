{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511eb14e-b585-4a46-bc12-250d2a348541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import IterableDataset, DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "from utilities.utility_functions import decompress_dict, pad_tensor\n",
    "from settings import MODEL_DATA_PATHS, DATA_BLUEPRINT, DATA_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8229b48-90b0-44b4-a9c5-5db568d1c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a67a30-6fd6-4081-8c3b-26506e9fbfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiplomacyDataset(IterableDataset):\n",
    "    def __init__(self, file_path: str, shuffle: bool, shuffle_buffer_size: int) -> None:\n",
    "        super(DiplomacyDataset).__init__()\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        self.shuffle = shuffle\n",
    "        self.shuffle_buffer_size = shuffle_buffer_size\n",
    "        \n",
    "        if self.shuffle and self.shuffle_buffer_size <= 1:\n",
    "            raise ValueError(\"Bad shuffle buffer size.\"\\\n",
    "                            \"If you want to shuffle the iterable data, you have to define a positive > 1 shuffle buffer size.\"\\\n",
    "                            f\"\\nGot 'shuffle': {self.shuffle}, shuffle_buffer_size: {self.shuffle_buffer_size}\")\n",
    "        \n",
    "    def sequential_iterator(self):\n",
    "        # return iter(range(100))\n",
    "        return open(self.file_path, \"r\")\n",
    "        \n",
    "    def shuffle_iterator(self):\n",
    "        shuffle_buffer = []\n",
    "        local_iterator = self.sequential_iterator()\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # fill up the initial buffer\n",
    "            for _ in range(self.shuffle_buffer_size):\n",
    "                shuffle_buffer.append(next(local_iterator))\n",
    "        except StopIteration:\n",
    "            # in the scenario of either too small dataset file or too big buffer size,\n",
    "            # shrink the shuffle buffer\n",
    "\n",
    "            LOGGER.info(\"Either the dataset file is too small, or shuffle buffer size is too big for the file. \"\\\n",
    "                        \"Shrinking the buffer...\")\n",
    "            self.shuffle_buffer_size = len(shuffle_buffer)\n",
    "            \n",
    "        # main loop\n",
    "        while True:\n",
    "            remove_index = random.randint(0, len(shuffle_buffer) - 1)\n",
    "            yield shuffle_buffer.pop(remove_index)\n",
    "            \n",
    "            try:\n",
    "                shuffle_buffer.append(next(local_iterator))\n",
    "            except StopIteration:\n",
    "                break\n",
    "                \n",
    "        while len(shuffle_buffer) > 0:\n",
    "            remove_index = random.randint(0, len(shuffle_buffer) - 1)\n",
    "            yield shuffle_buffer.pop(remove_index)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \n",
    "        if(self.shuffle):\n",
    "            self.iterator = self.shuffle_iterator()\n",
    "        else:\n",
    "            self.iterator = self.sequential_iterator()\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def __next__(self):\n",
    "        return decompress_dict( next(self.iterator) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f10c2af-7011-447c-b677-89fe6d820c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 120\n",
    "shuffle = False\n",
    "shuffle_buffer_size = 1\n",
    "file_path = \"data/model_data/full_dataset_training.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef11e484-f44d-409d-b156-a9551214f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiplomacyDataset(file_path = file_path, shuffle = shuffle, shuffle_buffer_size = shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07aa8a4e-ef8b-4803-8995-b583e267a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIABLE_LEN_FEATURES = [key for key, value in DATA_BLUEPRINT.items() if value[\"shape\"] == [None]]\n",
    "\n",
    "def custom_collate_fn(batch: dict, pad_batch: bool = False):\n",
    "    \"\"\"\n",
    "    Modified default pytorch collate function.\n",
    "    It is meant to collate the received dictionary values onto original keys,\n",
    "    also pad the non-fixed dimension features to max length of their group per batch.\n",
    "    \n",
    "    If you modify the project, please pay attention to this function,\n",
    "    as it single-purpose and should be extented.\n",
    "    \"\"\"\n",
    "    element = batch[0]\n",
    "    \n",
    "    # scalars\n",
    "    if isinstance(element, float):\n",
    "        return torch.tensor(batch, dtype=torch.float32)\n",
    "    elif isinstance(element, int):\n",
    "        return torch.tensor(batch, dtype=torch.int32)\n",
    "    elif isinstance(element, str):\n",
    "        return batch\n",
    "    \n",
    "    # lists NOTE: WORKS WITH ONLY 1-D lists!!!\n",
    "    elif isinstance(element, list):\n",
    "        first_list_element = element[0]\n",
    "        \n",
    "        # call collate_fn recursevly to get an the type of list elements\n",
    "        list_type = custom_collate_fn(element).dtype\n",
    "            \n",
    "        # pad the lists if needed\n",
    "        if pad_batch:\n",
    "            max_size = max([len(element) for element in batch])\n",
    "            batch = [element + [0]*(max_size - len(element)) for element in batch]\n",
    "        \n",
    "        return torch.tensor(batch, dtype = list_type)\n",
    "    \n",
    "    # call collate_fn recursevely to collate all values of the keys amongst the batch of dictionaries\n",
    "    elif isinstance(element, dict):\n",
    "        return dict(\n",
    "            {\n",
    "                key: custom_collate_fn(\n",
    "                    batch = [dictionary[key] for dictionary in batch],\n",
    "                    pad_batch = key in VARIABLE_LEN_FEATURES\n",
    "                ) for key in element\n",
    "            }\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeb57339-7654-4ef4-848f-df393604c5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['board_alignments', 'decoder_inputs', 'candidates']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VARIABLE_LEN_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80a18a81-b689-4857-8ea6-cbeb5308ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size = batch_size, collate_fn = custom_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75382c7-0972-42b3-aaff-dde140491442",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d85d92c-96d4-4df6-81de-1f2c980f980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, inputs: dict):\n",
    "        \n",
    "        # the inputs are:\n",
    "        #board_state - torch.float - (b, N_NODES, N_FEATURES)\n",
    "        #board_alignments - torch.float - (b, N_NODES * len)\n",
    "        #prev_orders_state - torch.float - (b, N_PREV_ORDERS, N_NODES, N_ORDERS_FEATURES)\n",
    "        #decoder_inputs - torch.int - (b, <= 1 + N_SUPPLY_CENTERS)\n",
    "        #decoder_lengths - torch.int - (b,)\n",
    "        #candidates - torch.int - (b, n_locs * MAX_CANDIDATES)\n",
    "        #current_power - torch.int - (b,)\n",
    "        #current_season - torch.int - (b,)\n",
    "        #dropout_rates - torch.int - (b,)\n",
    "        \n",
    "        # recast some features to float dtype\n",
    "        inputs[\"board_state\"] = inputs[\"board_state\"].to(torch.float32)\n",
    "        inputs[\"board_alignments\"] = inputs[\"board_alignments\"].to(torch.float32)\n",
    "        inputs[\"prev_orders_state\"] = inputs[\"prev_orders_state\"].to(torch.float32)\n",
    "        \n",
    "        # variables for data processing\n",
    "        batch_size = inputs[\"board_state\"].shape[0]\n",
    "        max_decoder_length = int(torch.max(inputs[\"decoder_lengths\"]))\n",
    "        \n",
    "         # Reshaping board alignments - NEED TO REMOVE SINCE IT\"S MANUAL DE-FLATTENING\n",
    "        inputs[\"board_alignments\"] = torch.reshape(\n",
    "            inputs[\"board_alignments\"], (batch_size, -1, DATA_FEATURES[\"N_NODES\"])\n",
    "        )\n",
    "              \n",
    "        inputs[\"board_alignments\"] /= torch.maximum(\n",
    "            torch.tensor(1.), torch.sum(\n",
    "                inputs[\"board_alignments\"], dim=-1, keepdims=True\n",
    "            )\n",
    "        )\n",
    "        \n",
    "          # this below is litteraly useless!!!!\n",
    "#         # Overriding dropout_rates if pholder('dropout_rate') > 0\n",
    "#         dropout_rates = tf.cond(tf.greater(pholder('dropout_rate'), 0.),\n",
    "#                                 true_fn=lambda: tf.zeros_like(dropout_rates) + pholder('dropout_rate'),\n",
    "#                                 false_fn=lambda: dropout_rates)\n",
    "\n",
    "        # Padding decoder_inputs and candidates\n",
    "        # THIS BELOW COULD BE USELESS useless!!!!\n",
    "        # implement this if problems arise\n",
    "        inputs[\"board_alignments\"] = pad_tensor(inputs[\"board_alignments\"], axis = 1, min_size = max_decoder_length)\n",
    "        inputs[\"decoder_inputs\"] = pad_tensor(inputs[\"decoder_inputs\"], axis = -1, min_size = 2)\n",
    "        inputs[\"candidates\"] = pad_tensor(inputs[\"candidates\"], axis = -1, min_size = DATA_FEATURES[\"MAX_CANDIDATES\"])\n",
    "\n",
    "\n",
    "        # Making sure all RNN lengths are at least 1\n",
    "        # No need to trim, because the fields are variable length\n",
    "        inputs[\"raw_decoder_lengths\"] = inputs[\"decoder_lengths\"]\n",
    "        inputs[\"decoder_lengths\"] = torch.maximum(torch.tensor(1), inputs[\"decoder_lengths\"])\n",
    "        \n",
    "        # Placeholders\n",
    "        # TODO: figure out what is this decoder_type used for\n",
    "        # decoder_type = tf.reduce_max(pholder('decoder_type'))\n",
    "        # this is possibly useless here\n",
    "        # is_training = pholder('is_training')\n",
    "\n",
    "        # Reshaping candidates\n",
    "        inputs[\"candidates\"] = torch.reshape(inputs[\"candidates\"], (batch_size, -1, DATA_FEATURES[\"MAX_CANDIDATES\"]))\n",
    "        inputs[\"candidates\"] = inputs[\"candidates\"][:, :max_decoder_length, :] # torch.int - (b, n_locs, MAX_CANDIDATES)      \n",
    "                \n",
    "        # Computing FiLM Gammas and Betas\n",
    "                with tf.variable_scope('film_scope'):\n",
    "                    power_embedding = uniform(name='power_embedding',\n",
    "                                              shape=[NB_POWERS, hps('power_emb_size')],\n",
    "                                              scale=1.)\n",
    "                    current_power_mask = tf.one_hot(current_power, NB_POWERS, dtype=tf.float32)\n",
    "                    current_power_embedding = tf.reduce_sum(power_embedding[None]\n",
    "                                                            * current_power_mask[:, :, None], axis=1)  # (b, power_emb)\n",
    "                    film_embedding_input = current_power_embedding\n",
    "\n",
    "                    # Also conditioning on current_season\n",
    "                    season_embedding = uniform(name='season_embedding',\n",
    "                                               shape=[NB_SEASONS, hps('season_emb_size')],\n",
    "                                               scale=1.)\n",
    "                    current_season_mask = tf.one_hot(current_season, NB_SEASONS, dtype=tf.float32)\n",
    "                    current_season_embedding = tf.reduce_sum(season_embedding[None]                 # (b,season_emb)\n",
    "                                                             * current_season_mask[:, :, None], axis=1)\n",
    "                    film_embedding_input = tf.concat([film_embedding_input, current_season_embedding], axis=1)\n",
    "\n",
    "                    film_output_dims = [hps('gcn_size')] * (hps('nb_graph_conv') - 1) + [hps('attn_size') // 2]\n",
    "\n",
    "                    # For board_state\n",
    "                    board_film_weights = tf.layers.Dense(units=2 * sum(film_output_dims),               # (b, 1, 750)\n",
    "                                                         use_bias=True,\n",
    "                                                         activation=None)(film_embedding_input)[:, None, :]\n",
    "                    board_film_gammas, board_film_betas = tf.split(board_film_weights, 2, axis=2)       # (b, 1, 750)\n",
    "                    board_film_gammas = tf.split(board_film_gammas, film_output_dims, axis=2)\n",
    "                    board_film_betas = tf.split(board_film_betas, film_output_dims, axis=2)\n",
    "\n",
    "                    # For prev_orders\n",
    "                    prev_ord_film_weights = tf.layers.Dense(units=2 * sum(film_output_dims),            # (b, 1, 750)\n",
    "                                                            use_bias=True,\n",
    "                                                            activation=None)(film_embedding_input)[:, None, :]\n",
    "                    prev_ord_film_weights = tf.tile(prev_ord_film_weights, [NB_PREV_ORDERS, 1, 1])      # (n_pr, 1, 750)\n",
    "                    prev_ord_film_gammas, prev_ord_film_betas = tf.split(prev_ord_film_weights, 2, axis=2)\n",
    "                    prev_ord_film_gammas = tf.split(prev_ord_film_gammas, film_output_dims, axis=2)\n",
    "                    prev_ord_film_betas = tf.split(prev_ord_film_betas, film_output_dims, axis=2)\n",
    "\n",
    "                    # Storing as temporary output\n",
    "                    self.add_output('_board_state_conv_film_gammas', board_film_gammas)\n",
    "                    self.add_output('_board_state_conv_film_betas', board_film_betas)\n",
    "                    self.add_output('_prev_orders_conv_film_gammas', prev_ord_film_gammas)\n",
    "                    self.add_output('_prev_orders_conv_film_betas', prev_ord_film_betas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "441c2903-ba44-482d-ae2e-043518b68b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3cdc1fac-0e11-4cab-a190-2c179bad42ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 4080])\n",
      "torch.Size([120, 17, 240])\n",
      "torch.Size([120, 17, 240])\n",
      "17\n",
      "torch.Size([120, 3120])\n",
      "torch.Size([120, 13, 240])\n",
      "torch.Size([120, 13, 240])\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "real_batch = None\n",
    "\n",
    "i = 0\n",
    "for batch in dataloader:\n",
    "    # print(batch)\n",
    "    # print(batch[\"request_id\"])\n",
    "    # print(batch[\"player_seed\"], batch[\"player_seed\"].shape)\n",
    "    # print(batch[\"board_state\"], batch[\"board_state\"].shape)\n",
    "    # print(batch[\"board_alignments\"], batch[\"board_alignments\"].shape) ## NEED TO DISABLE FLATTENING\n",
    "    # print(batch[\"prev_orders_state\"], batch[\"prev_orders_state\"].shape)\n",
    "    # print(batch[\"decoder_inputs\"], batch[\"decoder_inputs\"].shape)\n",
    "    # print(batch[\"decoder_lengths\"], batch[\"decoder_lengths\"].shape)\n",
    "    # print(batch[\"candidates\"], batch[\"candidates\"].shape)\n",
    "    # print(batch[\"noise\"], batch[\"noise\"].shape)\n",
    "    # print(batch[\"temperature\"], batch[\"temperature\"].shape, batch[\"temperature\"].dtype)\n",
    "    # print(batch[\"dropout_rate\"], batch[\"dropout_rate\"].shape, batch[\"dropout_rate\"].dtype)\n",
    "    # print(batch[\"current_power\"], batch[\"current_power\"].shape)\n",
    "    # print(batch[\"current_season\"], batch[\"current_season\"].shape)\n",
    "    # print(batch[\"draw_target\"], batch[\"draw_target\"].shape)\n",
    "    # print(batch[\"value_target\"], batch[\"value_target\"].shape)\n",
    "    real_batch = batch\n",
    "    encoder(real_batch)\n",
    "    if i == 1:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5112fa6f-8a7c-43ae-9279-7ba1a2e6b8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a72f978-031a-48ec-ba51-dc145b1aa71c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
