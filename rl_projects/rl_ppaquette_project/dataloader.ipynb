{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511eb14e-b585-4a46-bc12-250d2a348541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "from utilities.utility_functions import decompress_dict\n",
    "from settings import MODEL_DATA_PATHS, DATA_BLUEPRINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8229b48-90b0-44b4-a9c5-5db568d1c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6a67a30-6fd6-4081-8c3b-26506e9fbfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiplomacyDataset(IterableDataset):\n",
    "    def __init__(self, file_path, shuffle, shuffle_buffer_size) -> None:\n",
    "        super(DiplomacyDataset).__init__()\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        self.shuffle = shuffle\n",
    "        self.shuffle_buffer_size = shuffle_buffer_size\n",
    "        \n",
    "        if self.shuffle and self.shuffle_buffer_size <= 1:\n",
    "            raise ValueError(\"Bad shuffle buffer size.\"\\\n",
    "                            \"If you want to shuffle the iterable data, you have to define a positive > 1 shuffle buffer size.\"\\\n",
    "                            f\"\\nGot 'shuffle': {self.shuffle}, shuffle_buffer_size: {self.shuffle_buffer_size}\")\n",
    "        \n",
    "    def sequential_iterator(self):\n",
    "        # return iter(range(100))\n",
    "        return open(self.file_path, \"r\")\n",
    "        \n",
    "    def shuffle_iterator(self):\n",
    "        shuffle_buffer = []\n",
    "        local_iterator = self.sequential_iterator()\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # fill up the initial buffer\n",
    "            for _ in range(self.shuffle_buffer_size):\n",
    "                shuffle_buffer.append(next(local_iterator))\n",
    "        except StopIteration:\n",
    "            # in the scenario of either too small dataset file or too big buffer size,\n",
    "            # shrink the shuffle buffer\n",
    "\n",
    "            LOGGER.info(\"Either the dataset file is too small, or shuffle buffer size is too big for the file. \"\\\n",
    "                        \"Shrinking the buffer...\")\n",
    "            self.shuffle_buffer_size = len(shuffle_buffer)\n",
    "            \n",
    "        # main loop\n",
    "        while True:\n",
    "            remove_index = random.randint(0, len(shuffle_buffer) - 1)\n",
    "            yield shuffle_buffer.pop(remove_index)\n",
    "            \n",
    "            try:\n",
    "                shuffle_buffer.append(next(local_iterator))\n",
    "            except StopIteration:\n",
    "                break\n",
    "                \n",
    "        while len(shuffle_buffer) > 0:\n",
    "            remove_index = random.randint(0, len(shuffle_buffer) - 1)\n",
    "            yield shuffle_buffer.pop(remove_index)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \n",
    "        if(self.shuffle):\n",
    "            self.iterator = self.shuffle_iterator()\n",
    "        else:\n",
    "            self.iterator = self.sequential_iterator()\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def __next__(self):\n",
    "        item = next(self.iterator)\n",
    "        item = decompress_dict(item)\n",
    "        # del item[\"candidates\"]\n",
    "        # print(item[\"decoer_inputs\"])\n",
    "        # return {\"a\": item[\"request_id\"], \"b\": item[\"decoder_lengths\"]}\n",
    "        # return (12, \"ba\", np.array([4,5,6]))\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f10c2af-7011-447c-b677-89fe6d820c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "shuffle = False\n",
    "shuffle_buffer_size = 1\n",
    "file_path = \"data/model_data/full_dataset_training.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef11e484-f44d-409d-b156-a9551214f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiplomacyDataset(file_path = file_path, shuffle = shuffle, shuffle_buffer_size = shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07aa8a4e-ef8b-4803-8995-b583e267a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch, pad_batch = False):\n",
    "    \"\"\"\n",
    "    Modified default pytorch collate function.\n",
    "    It is meant to collate the received dictionary values onto original keys,\n",
    "    also pad the non-fixed dimension features to max length of their group per batch.\n",
    "    \n",
    "    If you modify the project, please pay attention to this function,\n",
    "    as it single-purpose and should be extented.\n",
    "    \"\"\"\n",
    "    element = batch[0]\n",
    "    \n",
    "    # scalars\n",
    "    if isinstance(element, float):\n",
    "        return torch.tensor(batch, dtype=torch.float32)\n",
    "    elif isinstance(element, int):\n",
    "        return torch.tensor(batch, dtype=torch.int32)\n",
    "    elif isinstance(element, str):\n",
    "        return batch\n",
    "    \n",
    "    # lists NOTE: WORKS WITH ONLY 1-D lists!!!\n",
    "    elif isinstance(element, list):\n",
    "        first_list_element = element[0]\n",
    "        \n",
    "        # call collate_fn recursevly to get an the type of list elements\n",
    "        list_type = custom_collate_fn(element).dtype\n",
    "            \n",
    "        # pad the lists if needed\n",
    "        if pad_batch:\n",
    "            max_size = max([len(element) for element in batch])\n",
    "            batch = [element + [0]*(max_size - len(element)) for element in batch]\n",
    "        \n",
    "        return torch.tensor(batch, dtype = list_type)\n",
    "    \n",
    "    # call collate_fn recursevely to collate all values of the keys amongst the batch of dictionaries\n",
    "    elif isinstance(element, dict):\n",
    "        return dict(\n",
    "            {\n",
    "                key: custom_collate_fn(\n",
    "                    [dictionary[key] for dictionary in batch],\n",
    "                    key in VARIABLE_LEN_FEATURES\n",
    "                ) for key in element\n",
    "            }\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80a18a81-b689-4857-8ea6-cbeb5308ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size = batch_size, collate_fn = custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3cdc1fac-0e11-4cab-a190-2c179bad42ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in dataloader:\n",
    "    # print(batch)\n",
    "    # print(batch[\"request_id\"])\n",
    "    # print(batch[\"player_seed\"], batch[\"player_seed\"].shape)\n",
    "    # print(batch[\"board_state\"], batch[\"board_state\"].shape)\n",
    "    # print(batch[\"board_alignments\"], batch[\"board_alignments\"].shape)\n",
    "    # print(batch[\"prev_orders_state\"], batch[\"prev_orders_state\"].shape)\n",
    "    # print(batch[\"decoder_inputs\"], batch[\"decoder_inputs\"].shape)\n",
    "    # print(batch[\"decoder_lengths\"], batch[\"decoder_lengths\"].shape)\n",
    "    # print(batch[\"candidates\"], batch[\"candidates\"].shape)  ## need to flatten\n",
    "    # print(batch[\"noise\"], batch[\"noise\"].shape)\n",
    "    # print(batch[\"temperature\"], batch[\"temperature\"].shape, batch[\"temperature\"].dtype)\n",
    "    # print(batch[\"dropout_rate\"], batch[\"dropout_rate\"].shape, batch[\"dropout_rate\"].dtype)\n",
    "    # print(batch[\"current_power\"], batch[\"current_power\"].shape)\n",
    "    # print(batch[\"current_season\"], batch[\"current_season\"].shape)\n",
    "    # print(batch[\"draw_target\"], batch[\"draw_target\"].shape)\n",
    "    # print(batch[\"value_target\"], batch[\"value_target\"].shape)\n",
    "    if i == 0:\n",
    "        break\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
